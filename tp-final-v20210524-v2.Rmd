---
title: "Trabajo Final - Estadistica Espacial"
output: html_notebook
---

Cargamos los paquetes necesarios
```{r}
library(dplyr)
library(sf)
library(gstat)
library(geoR)
library(spdep)
library(DataExplorer)
library(psych)
library(ggcorrplot)
library(biogeo)
library(ggplot2)
library(leaflet)
```
Cargamos los datasets
```{r}
estaciones <- read.csv("data_smn/preprocessed/estaciones_smn_v2.csv")
horarios <- read.csv("data_smn/preprocessed/datohorario20210420.csv")
```

Observamos como esta compuesto el dataset
```{r}
glimpse(estaciones)
print("#--------------------#")
glimpse(horarios)
```
Observamos que la variable que representa la velocidad del viento en km/h (FF) es de tipo Char, por lo cual debemos convertila en int.
```{r}
horarios$FF <- as.numeric(horarios$FF)
```

Observamos el resumen estadistico de las variables de potencial interes
```{r}
print("altura")
summary(estaciones$ALTURA)
print("hora")
summary(horarios$HORA)
print("temperatura")
summary(horarios$TEMP)
print("humedad")
summary(horarios$HUM)
print("presion atmosferica")
summary(horarios$PNM)
print("direccion del viento")
summary(horarios$DD)
print("velocidad del viento")
summary(horarios$FF)
```
Se puede observar la presencia de observaciones NA's, por lo cual procedemos a eliminarlas
```{r}
which(is.na(horarios), arr.ind=TRUE)
```
```{r}
horarios[771,]
```
Como toda la fila para la rioja aero es NA, lla eliminamos
```{r}
horarios <- horarios[-c(771), ]  
rownames(horarios) <- 1:nrow(horarios)
```

```{r}
horarios[587,]
```
Completamos la columna humedad con el promedio
```{r}
# FORMOSA AERO
formosa <- horarios[horarios$NOMBRE == "FORMOSA AERO",]
which(is.na(formosa), arr.ind=TRUE)
```

```{r}
formosa <- na.omit(formosa)
horarios[587,4] = mean(formosa$HUM)
horarios[587,]

remove(formosa)
```
```{r}
which(is.na(horarios), arr.ind=TRUE)
```

```{r}
horarios[c(1875,1876),]
```
Completamos con el promedio de humedad calculado para tucuman aero
```{r}
# TUCUMAN AERO
tucuman_aero <- horarios[horarios$NOMBRE == "TUCUMAN AERO",]
which(is.na(tucuman_aero), arr.ind=TRUE)
```
```{r}

tucuman_aero <- na.omit(tucuman_aero)
horarios[1875,4] = mean(tucuman_aero$HUM)
horarios[1876,4] = mean(tucuman_aero$HUM)
horarios[c(1875,1876),]

remove(tucuman_aero)
```
```{r}
horarios[237,]
```

```{r}
# CATAMARCA AERO
catamarca_aero <- horarios[horarios$NOMBRE == "CATAMARCA AERO",]
which(is.na(catamarca_aero), arr.ind=TRUE)
```
```{r}
catamarca_aero <- na.omit(catamarca_aero)
horarios[237,5] = mean(catamarca_aero$PNM)
horarios[237,]
remove(catamarca_aero)
```
```{r}
horarios[c(972,973,974,975,976,977,978,979),]
```

```{r}
# MERCEDES AERO
mercedes_aero <- horarios[horarios$NOMBRE == "MERCEDES AERO",]
which(is.na(mercedes_aero), arr.ind=TRUE)
remove(mercedes_aero)
```
Vamos a completar los valores faltantes para la presion atmosferica con el promedio de la provincia de corrientes a la que pertenece Mercedes aero
```{r}
corrientes_aero <- horarios[(horarios$NOMBRE == "CORRIENTES AERO") | (horarios$NOMBRE == "ITUZAINGO") | (horarios$NOMBRE == "MONTE CASEROS AERO") | (horarios$NOMBRE == "PASO DE LOS LIBRES AERO"),]
which(is.na(corrientes_aero), arr.ind=TRUE)

horarios[972,5] = mean(corrientes_aero$PNM)
horarios[973,5] = mean(corrientes_aero$PNM)
horarios[974,5] = mean(corrientes_aero$PNM)
horarios[975,5] = mean(corrientes_aero$PNM)
horarios[976,5] = mean(corrientes_aero$PNM)
horarios[977,5] = mean(corrientes_aero$PNM)
horarios[978,5] = mean(corrientes_aero$PNM)
horarios[979,5] = mean(corrientes_aero$PNM)

horarios[c(972,973,974,975,976,977,978,979),]
remove(corrientes_aero)
```
```{r}
horarios[c(1391,1392,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403),]
```

```{r}
# RIO GALLEGOS AERO
gallegos_aero <- horarios[horarios$NOMBRE == "RIO GALLEGOS AERO",]
which(is.na(gallegos_aero), arr.ind=TRUE)
```
```{r}
gallegos_aero <- na.omit(gallegos_aero)
horarios[1391,5] = mean(gallegos_aero$PNM)
horarios[1392,5] = mean(gallegos_aero$PNM)
horarios[1393,5] = mean(gallegos_aero$PNM)
horarios[1394,5] = mean(gallegos_aero$PNM)
horarios[1395,5] = mean(gallegos_aero$PNM)
horarios[1396,5] = mean(gallegos_aero$PNM)
horarios[1397,5] = mean(gallegos_aero$PNM)
horarios[1398,5] = mean(gallegos_aero$PNM)
horarios[1399,5] = mean(gallegos_aero$PNM)
horarios[1400,5] = mean(gallegos_aero$PNM)
horarios[1401,5] = mean(gallegos_aero$PNM)
horarios[1402,5] = mean(gallegos_aero$PNM)
horarios[1403,5] = mean(gallegos_aero$PNM)
horarios[c(1391,1392,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403),]
remove(gallegos_aero)
```
```{r}
which(is.na(horarios), arr.ind=TRUE)
```
```{r}
horarios[1440,]
```
```{r}
# RIO GRANDE
rio_grande_aero <- horarios[horarios$NOMBRE == "RIO GRANDE B.A.",]
which(is.na(rio_grande_aero), arr.ind=TRUE)
```
```{r}
rio_grande_aero <- na.omit(rio_grande_aero)
horarios[1440,5] = mean(rio_grande_aero$PNM)
horarios[1440,]

remove(rio_grande_aero)
```
Validamos que efectivamente se hayan arreglado
```{r}
print("temperatura")
summary(horarios$TEMP)
print("humedad")
summary(horarios$HUM)
print("presion atmosferica")
summary(horarios$PNM)
print("direccion del viento")
summary(horarios$DD)
print("velocidad del viento")
summary(horarios$FF)
```
Perfecto, ya no tenemos valores nulos en nuestro dataset.

# Analisis descriptivo de las variables

A continuación, visualizaremos las distribuciones de las variables numericas de interés
```{r}
hist(estaciones$ALTURA, main = "Histograma de la altura", xlab = "Altura")
hist(horarios$HORA, main = "Histograma de horarios", xlab = "Horarios")
hist(horarios$TEMP, main = "Histograma de temperatura", xlab = "Temperatura")
hist(horarios$HUM, main = "Histograma de humedad", xlab = "Humedad")
hist(horarios$PNM, main = "Histograma de presion atmosferica", xlab = "Presion Atmosferica")
hist(horarios$DD, main = "Histograma de la direccion del viento", xlab = "Direccion del viento")
hist(horarios$FF, main = "Histograma de la velocidad del viento", xlab = "Velocidad del viento")
```
Creamos unos boxplot para visualizar la distribucionde datos que potencialmente nos interecen para proceder con el analisis
```{r}
boxplot(estaciones$ALTURA, main = "Boxplot de la altura", xlab = "Altura")
boxplot(horarios$HORA, main = "Boxplot de horarios", xlab = "Horarios")
boxplot(horarios$TEMP, main = "Boxplot de temperatura", xlab = "Temperatura")
boxplot(horarios$HUM, main = "Boxplot de humedad", xlab = "Humedad")
boxplot(horarios$PNM, main = "Boxplot de presion atmosferica", xlab = "Presion Atmosferica")
boxplot(horarios$DD, main = "Boxplot de la direccion del viento", xlab = "Direccion del viento")
boxplot(horarios$FF, main = "Boxplot de la velocidad del viento", xlab = "Velocidad del viento")
```
Los boxplots anteriores ponen en evidencia la existencia de outliers. ¿Pero son estos realmente outliers, o pertenecen a observaciones en lugares muy remotos? Esto lo analizaremos luego, al momento de graficar las estaciones en el mapa de Argentina.

Ahora, veamos que tan correlacionadas estan estas variables.
```{r}
corr <- cor(horarios[, c(2,3,4,5,6,7)], use = "complete.obs")

ggcorrplot(corr, type = "lower", outline.col = "black",
 lab=TRUE,
 ggtheme = ggplot2::theme_gray,
 colors = c("#6D9EC1", "white", "#E46726"))
```
Las variables que mas correlacionan con la velocidad del viento son HUMEDAD (negativamente) y HORA (positivamente).
Tambien vemos que HORA y TEMPERATURA correlacionan negativamentecon HUMEDAD.
Por ultimo, se observa que HORA y TEMPERATURA correlacionan positivamente

Analizamos ahora la simetria de la variable que representa la velocidad del viento ya que es la que mas nos interesa en este estudio.
```{r}
skew(horarios$FF)
kurtosi(horarios$FF)
```
La medida de asimetria y kurtosi terminan de validar lo que observamos en el histograma. La variable FF es asimetrica a derecha y tiene una mayor concentracion de valores muy cerca de la media de la distribución y muy lejos de la cola de la distribucion.

# Preprocesamiento de dataset
Un detalle no menor del dataset de estaciones es que las latitudes y longitudes estan expresadads en grados y minutos. Para poder trabajar con ellas, necesitamos que esten expresadas en valores decimales. Por eso, en el siguiente bloque de código vamos a usar la funcion dms2dd para hacer esta conversión.
```{r}
# creamos dos vectores vacios
latitud <- c()
longitud <- c()

# iteramos por cada fila del dataset de estaciones y hacemos la convesion de latitud y longitud
for(i in 1:nrow(estaciones)) {
     latitud[i] <- dms2dd(dd = estaciones[i, "LATITUD_GRADOS"], mm = estaciones[i, "LATITUD_MINUTOS"], ss = 0, ns = "S")
     longitud[i] <- dms2dd(dd = estaciones[i, "LONGITUD_GRADOS"], mm = estaciones[i, "LONGITUD_MINUTOS"], ss = 0, ns = "S")
}

# asignamos a latitud y longitud los valores convertidos
estaciones['LATITUD'] <- latitud
estaciones['LONGITUD'] <- longitud
```
Antes de unir estaciones, se removeran las columnas que no sean relevantes para este analisis. Las mismas son NRO y NroOACI, LATITUD_GRADOS, LATITUD_MINUTOS, LONGITUD_GRADOS, LONGITUD_MINUTOS. Asi como tambien se removera la variable fecha, ya que estos datos pertenecen al 20/04/2021
```{r}
estaciones <- estaciones[c(1,2,7,10,11)]
horarios <- horarios[,c(3,4,5,6,7,8)]
```

```{r}
summary(estaciones)
summary(horarios$TEMP)
```

Se procede a unificar las dos tablas usando la variable NOMBRE como punto para combinar los datasets
```{r}
data <- inner_join(estaciones, horarios, by = c("NOMBRE" = "NOMBRE"))

glimpse(data)
```
```{r}
summary(data$NOMBRE)
summary(data$PROVINCIA)
summary(data$ALTURA)
summary(data$LATITUD)
summary(data$LONGITUD)
summary(data$TEMP)
summary(data$HUM)
summary(data$PNM)
summary(data$DD)
summary(data$FF)
```
Volvemos realizar el grafico de correlacion incluyendo la variable altura.
```{r}
corr <- cor(data[, c(3,4,5,6,7,8,9,10)], use = "complete.obs")

ggcorrplot(corr, type = "lower", outline.col = "black",
 lab=TRUE,
 ggtheme = ggplot2::theme_gray,
 colors = c("#6D9EC1", "white", "#E46726"))
```
# TODO: AGREGAR CONCLUSION DEL GRAFICO DE CORRELACION

Se observa que hay estaciones que tiene las observaciones en 0 para la variable FF y DD. Consideramos esto como un error en el instrumento de medicion, por lo cual vamos a eliminar a esa estacion del analisis.
```{r}
data = data[(data$FF != 0) & (data$DD != 0),]
rownames(data) <- 1:nrow(data)
```

Agrupamos los datos por nombre calculando el promedio y desvio del viento
```{r}
data_agg = data %>%
  group_by(NOMBRE) %>%
  summarise(MEAN_VIENTO_KMH = mean(FF), 
            SD_VIENTO_KMH = sd(FF), 
            LONGITUD = unique(LONGITUD), 
            LATITUD = unique(LATITUD), 
            .groups = "keep")
```
Vemos que en el dataset resultante nos quedan 98 observaciones que coinciden con la cantidad de estaciones meteorologicas originales


Convertimos data_agg a data.frame ya que necesitamos este tipo de dato para poder trabajar
```{r}
data_agg = data.frame(data_agg)
```

Transformamos df_data_agg en un archivo geográfico utilizando el código de proyección mercator
```{r}
data_agg_sf = st_as_sf(data_agg, coords = c("LONGITUD", "LATITUD"), crs = 4326)
```

Validamos la clase del nuevo dataframe
```{r}
class(data_agg_sf)
```

# Analisis exploratorio espacial

## Grafico de las estaciones meteorologias
En el siguiente gráfico de la republica argentina se observan en color azul las estaciones meteorológicas donde se realizaron las mediciones de la variables que estan presentes en el dataset

Queremos que en el mapa se vea como etiqueta el nombre de la base meteorologica. Para eso aplicamos la siguiente funcion
```{r}
labs <- lapply(seq(nrow(data_agg_sf)), function(i) {
  paste0( '<p>', data_agg_sf[i, "NOMBRE"], '<p>', '<p>',data_agg_sf[i, "MEAN_VIENTO_KMH"],'</p>' ) })
```

Realizamos el grafico interactivo de las estaciones meteorologicas graficadas sobre un mapa de Argentina.
```{r}
leaflet() %>%
  addTiles() %>%
  addCircles(data = data_agg_sf, weight = 3, label = lapply(labs, htmltools::HTML))

```

# Limpieza de datos
En el mapa observamos que hay puntos muy distantes de la Argentina continental. Dado el proposito de este estudio, el cual es determinar la ubicacion geografica óptima en base a la variable velocidad del viento, decidimos remover estas observaciones ya que no aporta informacion util y ademas agregan ruido a nuestro analisis.

Primero, vamos a borrar las estaciones que no estan en la plataforma continental argentina
- Base Carlini
- Base San Martin
- Base Marambio
- Base Esperanza
- Base Orcadas

```{r}
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "BASE CARLINI (EX JUBANY)",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "BASE SAN MARTIN",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "BASE MARAMBIO",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "BASE ESPERANZA",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "BASE ORCADAS",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "BASE BELGRANO II",]
```

Repetimos el plot para validar
```{r}
labs <- lapply(seq(nrow(data_agg_sf)), function(i) {
  paste0( '<p>', data_agg_sf[i, "NOMBRE"], '</p>' ) })


leaflet() %>%
  addTiles() %>%
  addCircles(data = data_agg_sf, weight = 3, label = lapply(labs, htmltools::HTML))

```

Observemos el resumen estadistico de las nuevas variables MEAN_VIENTO_KMH y SD_VIENTO_KMH 
```{r}
describe(data_agg_sf$MEAN_VIENTO_KMH)
hist(data_agg_sf$MEAN_VIENTO_KMH)
boxplot(data_agg_sf$MEAN_VIENTO_KMH)
```
```{r}
describe(data_agg_sf$SD_VIENTO_KMH)
hist(data_agg_sf$SD_VIENTO_KMH)
boxplot(data_agg_sf$SD_VIENTO_KMH)
```
Veamos si esta nueva variable MEAN_VIENTO_KMH es normal.
```{r}
hist(data_agg_sf$MEAN_VIENTO_KMH)
boxplot(data_agg_sf$MEAN_VIENTO_KMH)
qqnorm(data_agg_sf$MEAN_VIENTO_KMH)
qqline(data_agg_sf$MEAN_VIENTO_KMH, col=2)
shapiro.test(data_agg_sf$MEAN_VIENTO_KMH)
```
Claramente la variable MEAN_VIENTO_KMH no es normal. El qqplot pone en evidencia la existencia de colas pesadas. Ademas, al realizar el test de shapiro wilk el p-value obtenido es menor a 0.05, lo cual indica que los datos que tenemos no son normales
#TODO: agregar algo mas a esta conclusion?

Ahora, procedemos a analizar la existencia de inliers, y en el caso de encontrarlos, eliminarlos.Para eso, usamos el test de moran. Basicamente lo que estamos testeando es que el promedio del viento este dristribuido de manera aleatoria siguiendo un proceso aleatorio.
```{r}
knea <- knearneigh(data_agg_sf)
neib <- knn2nb(knea)

listw <- nb2listw(neib)

moran_test <- moran.test(data_agg_sf$MEAN_VIENTO_KMH, listw)
moran_test
geary_test <- geary.test(data_agg_sf$MEAN_VIENTO_KMH, listw)
geary_test

shaphiro_test <- shapiro.test(data_agg_sf$MEAN_VIENTO_KMH)
shaphiro_test
```

```{r}
moran <- moran.plot(data_agg_sf$MEAN_VIENTO_KMH, listw = listw)
```

```{r}
data_agg_sf[10,]
data_agg_sf[31,]
data_agg_sf[79,]
data_agg_sf[108,]
data_agg_sf[68,]
data_agg_sf[21,]
data_agg_sf[89,]
data_agg_sf[23,]
data_agg_sf[109,]
```
```{r}
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "CATAMARCA AERO",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "GENERAL PICO AERO",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "RIO CUARTO AERO",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "VENADO TUERTO AERO",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "PIGUE AERO",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "CORONEL SUAREZ AERO",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "SAN LUIS AERO",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "DOLORES AERO",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "VICTORICA",]
rownames(data_agg_sf) <- 1:nrow(data_agg_sf)
```

# Inliers: verificamos los resultados dsp de eliminar inliers
```{r}
# Creamos una lista de vecinos
knea <- knearneigh(data_agg_sf)
neib <- knn2nb(knea)
listw <- nb2listw(neib)

# Hacemos el test de moran 
moran_test_v2 <- moran.test(data_agg_sf$MEAN_VIENTO_KMH, listw)
moran_test_v2

geary_test_v2 <- geary.test(data_agg_sf$MEAN_VIENTO_KMH, listw)
geary_test_v2

shaphiro_test_v2 <- shapiro.test(data_agg_sf$MEAN_VIENTO_KMH)
shaphiro_test_v2
```
```{r}
moran.plot(data_agg_sf$MEAN_VIENTO_KMH, listw = listw)
qqnorm(data_agg_sf$MEAN_VIENTO_KMH)
qqline(data_agg_sf$MEAN_VIENTO_KMH, col=2)
```
```{r}
data_agg_sf[56,]
data_agg_sf[96,]
```

```{r}
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "OBERA",]
data_agg_sf = data_agg_sf[data_agg_sf$NOMBRE != "TRENQUE LAUQUEN",]
rownames(data_agg_sf) <- 1:nrow(data_agg_sf)
```

```{r}
# Creamos una lista de vecinos
knea <- knearneigh(data_agg_sf)
neib <- knn2nb(knea)
listw <- nb2listw(neib)

# Hacemos el test de moran 
moran_test_v2 <- moran.test(data_agg_sf$MEAN_VIENTO_KMH, listw)
moran_test_v2

geary_test_v2 <- geary.test(data_agg_sf$MEAN_VIENTO_KMH, listw)
geary_test_v2

shaphiro_test_v2 <- shapiro.test(data_agg_sf$MEAN_VIENTO_KMH)
shaphiro_test_v2
```
```{r}
moran.plot(data_agg_sf$MEAN_VIENTO_KMH, listw = listw)
qqnorm(data_agg_sf$MEAN_VIENTO_KMH)
qqline(data_agg_sf$MEAN_VIENTO_KMH, col=2)
```

```{r}
# CALCULAMOS EL COEFICIENTE DE MORAN Y EL DE GEARY
moran(data_agg_sf$MEAN_VIENTO_KMH, listw, length(listw$weights),Szero(listw),zero.policy = FALSE)
```
#TODO: Agregar conclusion aca
```{r}
plot(data_agg_sf$MEAN_VIENTO_KMH)
```
# Variograma
```{r}
v <- variogram(MEAN_VIENTO_KMH~1, data_agg_sf)
plot(v)
```
```{r}
vt_exp = fit.variogram(v, vgm(125, "Exp", 30, 5))
vt_exp
plot(v , vt_exp)
```
```{r}
vt_mat = fit.variogram(v, vgm(125, "Mat", 30, 5))
plot(v , vt_mat)
```
```{r}
vt_exc = fit.variogram(v, vgm(125, "Exc", 30, 5))
plot(v , vt_exc)
```
```{r}
vt_bes = fit.variogram(v, vgm(125, "Bes", 30, 5))
plot(v , vt_bes)
```
```{r}
attr(vt_exp, 'SSErr')
attr(vt_mat, 'SSErr')
attr(vt_exc, 'SSErr')
attr(vt_bes, 'SSErr')
```

Kriging

```{r}
departamentos <- st_read("data_departamentos/Codgeo_Pais_x_dpto_con_datos/pxdptodatosok.shp")
departamentos <-departamentos[departamentos$departamen != "Antártida Argentina",]
departamentos <-departamentos[departamentos$departamen != "Islas del Atlántico Sur",]
departamentos <- as_Spatial(departamentos)
grilla <- as.data.frame(spsample(departamentos, type="regular", n=5000))
names(grilla) <- c("X", "Y")
coordinates(grilla) <- c("X", "Y")
plot(grilla)
gridded(grilla) <- TRUE
fullgrid(grilla) <- TRUE
plot(grilla)
proj4string(grilla) <- proj4string(departamentos)
data_agg_sf <- as_Spatial(data_agg_sf)
proj4string(data_agg_sf) <- proj4string(departamentos)
```
```{r}
ko1 <- krige(MEAN_VIENTO_KMH~1, data_agg_sf, grilla, model = vt_exp, nmax=20)
```
```{r}
spplot(ko1["var1.pred"])
spplot(ko1["var1.var"])
```
```{r}
ko2 <- krige(MEAN_VIENTO_KMH~1, data_agg_sf, grilla, model = vt_exp, nmax=50)
spplot(ko2["var1.pred"])
spplot(ko2["var1.var"])
```
```{r}
ko3 <- krige(MEAN_VIENTO_KMH~1, data_agg_sf, grilla, model = vt_bes, nmax=50)
spplot(ko3["var1.pred"])
spplot(ko3["var1.var"])
```

```{r}
library(raster)
r <- raster(ko1)
r.m <- mask(r, departamentos)
```

```{r}
library(tmap)
tm_shape(r.m) +
  tm_raster(n=10, 
            palette="Blues",
            auto.palette.mapping=FALSE,
title="") +
tm_legend(legend.outside=TRUE)
```
```{r}
r <- raster(ko1, layer="var1.var")
r.m <- mask(r, departamentos)

tm_shape(r.m) +
tm_raster(n=7, 
          palette ="Reds",
          title="Variance map ") +
tm_legend(legend.outside=TRUE)
```
```{r}
r <- sqrt(raster(ko1, layer="var1.var")) * 1.96
r.m <- mask(r, departamentos)

tm_shape(r.m) +
tm_raster(n=7, 
          palette ="Reds",
          title="95% CI map \n(en km/h)") +
tm_legend(legend.outside=TRUE)
```



